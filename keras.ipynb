{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAatQj1SPS0Okl0JZBnWTE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laurenwinslett/helloAI/blob/main/keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mwFpjBwP4w6",
        "outputId": "52f7dde9-bc0d-44c6-93c9-db1e996e22a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "before converting... 5\n",
            "7\n",
            "after converting y... [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "6000/6000 [==============================] - 31s 5ms/step - loss: 0.3259 - accuracy: 0.9112 - val_loss: 0.1909 - val_accuracy: 0.9447\n",
            "Test loss: 0.19086527824401855\n",
            "Test accuracy: 0.9447000026702881\n"
          ]
        }
      ],
      "source": [
        "# based on https://www.sitepoint.com/keras-digit-recognition-tutorial/\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import keras.datasets.mnist as kdm\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# tf.config.set_visible_devices([], 'GPU') # if you have an m1/m2 mac, uncomment this line to run wayyyy faster if you have local install of jupyter. leave commented if you are running on google colab \n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = kdm.load_data()\n",
        "assert x_train.shape == (60000, 28, 28)\n",
        "assert x_test.shape == (10000, 28, 28)\n",
        "assert y_train.shape == (60000,)\n",
        "assert y_test.shape == (10000,)\n",
        "\n",
        "print(\"before converting...\", y_train[0])\n",
        "\n",
        "# reshape\n",
        "img_rows, img_cols = 28, 28\n",
        "# normalize inputs to between 0 and 1\n",
        "import numpy as np\n",
        "x_train = np.true_divide(x_train, 255)\n",
        "x_test = np.true_divide(x_test, 255)\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "print(y_test[0])\n",
        "\n",
        "# convert to vector outputs \n",
        "num_classes = 10\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "print(\"after converting y...\", y_test[0])\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "  layers.Flatten(input_shape=(28,28)),\n",
        "  layers.Dense(100, activation='sigmoid'),\n",
        "  layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "      optimizer='adam',\n",
        "      metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=10,\n",
        "          epochs=1,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "model.save(\"test_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def findTroublesomeImageKERAS(model, x_test):\n",
        "  worsta = 1\n",
        "  worsti = 0\n",
        "  for i in range(len(x_test)):\n",
        "    prediction = model.predict(x_test[i], verbose=False)\n",
        "    max_a = np.max(prediction)\n",
        "    if max_a < worsta:\n",
        "      worsta = max_a\n",
        "      worsti = i\n",
        "  return (worsta, worsti)\n"
      ],
      "metadata": {
        "id": "UHlx0irtQLYa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(score)\n",
        "#print(x_test[768])\n",
        "a = model.predict(x_test[768:769])\n",
        "print(a)\n",
        "print(y_test[768])\n",
        "troublesome = findTroublesomeImageKERAS(model, x_test)\n",
        "print(troublesome)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYeMzdo8QQWY",
        "outputId": "7ffbf189-83f6-4cbf-9254-66df2f82ac10"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.19086527824401855, 0.9447000026702881]\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "[[2.98515950e-08 9.98622537e-01 1.09197856e-04 3.33845062e-04\n",
            "  3.55239945e-06 1.28387168e-04 1.59682328e-04 3.10571959e-05\n",
            "  5.40286186e-04 7.14999405e-05]]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "(0.25720453, 4874)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = model.predict(x_test[2770])\n",
        "print(a)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.imshow(np.reshape(x_test[2770], (28,28)),cmap=\"gray_r\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "I7PaCDcqQTKq",
        "outputId": "1612c65c-e62d-44b9-cb53-ec16c6a957a7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "[[4.0646479e-05 1.6752593e-02 1.8291945e-02 6.9744915e-01 3.1991228e-02\n",
            "  2.1038240e-02 1.5415776e-01 2.9211294e-02 2.9795112e-02 1.2721306e-03]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9441674fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAANSElEQVR4nO3db6hc9Z3H8c/HmD7QNpJsriGkYrpFH+hC0zqGxYaSpVqjCEmfSPOgRBRTMJEWihiySOIT0XXTokYK6RqSXWpKoTEG1N1qCEhBihPJav5QdSXShHjvDcFoEawm331wj+Um3jlzM+fMnEm+7xcMM3O+c+b3ZcgnZ+45c87PESEAF79Lmm4AwGAQdiAJwg4kQdiBJAg7kMSlgxxs7ty5sXDhwkEOCaRy5MgRnThxwlPVKoXd9jJJT0iaIek/IuLRstcvXLhQ7Xa7ypAASrRarY61nr/G254h6WlJt0m6TtJK29f1+n4A+qvK3+yLJb0bEe9FxN8k/VbS8nraAlC3KmFfIOkvk54fLZadxfZq223b7fHx8QrDAaii73vjI2JLRLQiojUyMtLv4QB0UCXsxyRdNen514tlAIZQlbC/Luka29+w/RVJP5K0u562ANSt50NvEfG57bWS/kcTh962RsTB2joDUKtKx9kj4kVJL9bUC4A+4ueyQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQqTdls+4ikjyWdlvR5RLTqaApA/SqFvfAvEXGihvcB0Ed8jQeSqBr2kPQH2/tsr57qBbZX227bbo+Pj1ccDkCvqoZ9SUR8R9JtktbY/t65L4iILRHRiojWyMhIxeEA9KpS2CPiWHE/Juk5SYvraApA/XoOu+3LbX/ti8eSfiDpQF2NAahXlb3x8yQ9Z/uL93k2Iv67lq4A1K7nsEfEe5K+VWMvAPqIQ29AEoQdSIKwA0kQdiAJwg4kUceJMBeE+++/v7S+YMGC0vq6devqbAcYOLbsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5BEmuPsmzdvLq1fckn5/3tvv/12x9rdd99duu6SJUtK68AgsGUHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSTSHGfvJiJK69u2betYe+mll0rXvfbaa3tpaSjMmjWrtL506dLS+u7du2vs5mybNm0qrbdaTCo8GVt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiC4+w1GB0drVS/kL3wwguNjf3AAw+U1vfu3TugTi4MXbfstrfaHrN9YNKyObZftv1OcT+7v20CqGo6X+O3SVp2zrJ1kvZExDWS9hTPAQyxrmGPiFclnTxn8XJJ24vH2yWtqLctAHXrdQfdvIg4Xjz+QNK8Ti+0vdp223Z7fHy8x+EAVFV5b3xMnEHS8SySiNgSEa2IaI2MjFQdDkCPeg37qO35klTcj9XXEoB+6DXsuyWtKh6vkvR8Pe0A6Jeux9lt75C0VNJc20clbZD0qKTf2b5H0vuS7uxnk3Xodm7zvn37BtQJ6sL56uena9gjYmWH0vdr7gVAH/FzWSAJwg4kQdiBJAg7kARhB5JIc4rrrl27SuuHDx8urT/77LMda/0+lfLo0aOl9dOnT/d1/Couu+yyjrWHHnqodN0bbrihtH7TTTf11FNWbNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IIk0x9kXLFhQqX7zzTfX2c55mT27/OK9p06dGlAn52/+/Pkda5999lnpuk1+5hcjtuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kIQnJnQZjFarFe12e2DjXSwu5OPsZWyX1q+88spK73/ppZ1/RvL000+Xrrt06dLS+qxZs3ppqe9arZba7faUHyxbdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IIs357BeyHTt2lNYff/zxjrVDhw6VrnvixInSej+vSd/tNx6jo6N9G3vFihWl9bvuuqu0vnnz5tJ62fXym9J1y257q+0x2wcmLdto+5jt/cXt9v62CaCq6XyN3yZp2RTLfxkRi4rbi/W2BaBuXcMeEa9KOjmAXgD0UZUddGttv1l8ze/4423bq223bbfHx8crDAegil7D/itJ35S0SNJxSZs6vTAitkREKyJaIyMjPQ4HoKqewh4RoxFxOiLOSPq1pMX1tgWgbj2F3fbk6wP/UNKBTq8FMBy6Hme3vUPSUklzbR+VtEHSUtuLJIWkI5J+0r8WsWzZVAdDpl8v89hjj5XWP/nkk57fu6rXXnuttP7KK6/0bext27aV1j/88MPS+s6dO+trpiZdwx4RK6dY/EwfegHQR/xcFkiCsANJEHYgCcIOJEHYgSQ4xTW5Bx98sLGxu03ZvHbt2gF1cv527drVdAvnjS07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBcfaLwJkzZzrWPvroo9J1Z86cWWnsbsfKyy5lXXYJbEl6/vnne+qpDmXTPUvSmjVrBtRJfdiyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASHGe/ADz55JOl9bGxsY61Rx55pHTd66+/vrTebVrlblNCX6jWr19fWt+4ceNgGqkRW3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSILj7BeADRs2lNZPnTrV83sfPHiw53WbdsUVV5TWb7zxxo61zZs3l6579dVX99TTMOu6Zbd9le29tg/ZPmj7p8XyObZftv1OcT+7/+0C6NV0vsZ/LunnEXGdpH+WtMb2dZLWSdoTEddI2lM8BzCkuoY9Io5HxBvF448lHZa0QNJySduLl22XtKJPPQKowXntoLO9UNK3Jf1J0ryIOF6UPpA0r8M6q223bbfHx8er9AqggmmH3fZXJf1e0s8i4qyrGMbE2RJTnjEREVsiohURrZGRkUrNAujdtMJue6Ymgv6biNhZLB61Pb+oz5fU+dQrAI3reujNtiU9I+lwRPxiUmm3pFWSHi3um7vu70Xu3nvvLa0/9dRTHWuffvpp3e2cpdulqGfMmNHze996662l9fvuu6+0fsstt/Q89sVoOsfZvyvpx5Lesr2/WLZeEyH/ne17JL0v6c6+dAigFl3DHhF/lOQO5e/X2w6AfuHnskAShB1IgrADSRB2IAnCDiThbpcKrlOr1Yp2uz2w8bI4efJkx9rDDz/c17G7Hcu+4447+jo+ztZqtdRut6c8esaWHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeS4FLSF4E5c+Z0rD3xxBMD7ATDjC07kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJNE17Lavsr3X9iHbB23/tFi+0fYx2/uL2+39bxdAr6Zz8YrPJf08It6w/TVJ+2y/XNR+GRH/3r/2ANRlOvOzH5d0vHj8se3Dkhb0uzEA9Tqvv9ltL5T0bUl/Khattf2m7a22Z3dYZ7Xttu32+Ph4tW4B9GzaYbf9VUm/l/SziPhI0q8kfVPSIk1s+TdNtV5EbImIVkS0RkZGqncMoCfTCrvtmZoI+m8iYqckRcRoRJyOiDOSfi1pcf/aBFDVdPbGW9Izkg5HxC8mLZ8/6WU/lHSg/vYA1GU6e+O/K+nHkt6yvb9Ytl7SStuLJIWkI5J+0of+ANRkOnvj/yhpqvmeX6y/HQD9wi/ogCQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTgiBjeYPS7p/UmL5ko6MbAGzs+w9jasfUn01qs6e7s6Iqa8/ttAw/6lwe12RLQaa6DEsPY2rH1J9NarQfXG13ggCcIOJNF02Lc0PH6ZYe1tWPuS6K1XA+mt0b/ZAQxO01t2AANC2IEkGgm77WW2/2z7XdvrmuihE9tHbL9VTEPdbriXrbbHbB+YtGyO7Zdtv1PcTznHXkO9DcU03iXTjDf62TU9/fnA/2a3PUPS25JukXRU0uuSVkbEoYE20oHtI5JaEdH4DzBsf0/SXyX9Z0T8U7Hs3ySdjIhHi/8oZ0fEg0PS20ZJf216Gu9itqL5k6cZl7RC0l1q8LMr6etODeBza2LLvljSuxHxXkT8TdJvJS1voI+hFxGvSjp5zuLlkrYXj7dr4h/LwHXobShExPGIeKN4/LGkL6YZb/SzK+lrIJoI+wJJf5n0/KiGa773kPQH2/tsr266mSnMi4jjxeMPJM1rspkpdJ3Ge5DOmWZ8aD67XqY/r4oddF+2JCK+I+k2SWuKr6tDKSb+BhumY6fTmsZ7UKaYZvzvmvzsep3+vKomwn5M0lWTnn+9WDYUIuJYcT8m6TkN31TUo1/MoFvcjzXcz98N0zTeU00zriH47Jqc/ryJsL8u6Rrb37D9FUk/krS7gT6+xPblxY4T2b5c0g80fFNR75a0qni8StLzDfZylmGZxrvTNONq+LNrfPrziBj4TdLtmtgj/3+S/rWJHjr09Y+S/re4HWy6N0k7NPG17jNN7Nu4R9I/SNoj6R1Jr0iaM0S9/ZektyS9qYlgzW+otyWa+Ir+pqT9xe32pj+7kr4G8rnxc1kgCXbQAUkQdiAJwg4kQdiBJAg7kARhB5Ig7EAS/w+8iQpia6drKQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dec_to_binvector4(dec):\n",
        "  binstr = \"{0:04b}\".format(int(dec))\n",
        "  binvect = []\n",
        "  for b in binstr:\n",
        "    binvect.append(int(b))\n",
        "  return binvect\n",
        "\n",
        "# expects y_data to be a list of nonnegative integer numbers (e.g., 0, 1, 2, 3)\n",
        "# returns the binary representation of each y using the specified number of bits\n",
        "def to_binary(y_data):\n",
        "  return [np.array(dec_to_binvector4(y)).reshape(4, 1) for y in y_data]\n",
        "\n",
        "print(dec_to_binvector4(7))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBZSAFfjQWCi",
        "outputId": "0a990992-f234-40d1-f2f9-575202281855"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# based on https://www.sitepoint.com/keras-digit-recognition-tutorial/\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import keras.datasets.mnist as kdm\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = kdm.load_data()\n",
        "\n",
        "\n",
        "# reshape\n",
        "img_rows, img_cols = 28, 28\n",
        "# normalize inputs to between 0 and 1\n",
        "import numpy as np\n",
        "x_train = np.true_divide(x_train, 255)\n",
        "x_test = np.true_divide(x_test, 255)\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        "# convert to vector outputs \n",
        "num_classes = 10\n",
        "y_train = to_binary(y_train)\n",
        "y_test = to_binary(y_test)\n",
        "\n",
        "y_train = np.array(y_train).reshape(60000, 4)\n",
        "y_test = np.array(y_test).reshape(10000, 4)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "  layers.Flatten(input_shape=(28,28)),\n",
        "  layers.Dense(100, activation='sigmoid'),\n",
        "  layers.Dense(10, activation='sigmoid'),\n",
        "  layers.Dense(4, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "model.compile(loss='mean_squared_error',\n",
        "      optimizer='adam',\n",
        "      metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=10,\n",
        "          epochs=30,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "model.save(\"test_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JljWMwr_QYd-",
        "outputId": "1221e298-70ac-43c9-988c-763475ea5b90"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "6000/6000 [==============================] - 20s 3ms/step - loss: 0.0652 - accuracy: 0.5916 - val_loss: 0.0297 - val_accuracy: 0.6427\n",
            "Epoch 2/30\n",
            "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0224 - accuracy: 0.6590 - val_loss: 0.0198 - val_accuracy: 0.6524\n",
            "Epoch 3/30\n",
            "6000/6000 [==============================] - 17s 3ms/step - loss: 0.0154 - accuracy: 0.7009 - val_loss: 0.0157 - val_accuracy: 0.7189\n",
            "Epoch 4/30\n",
            "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0122 - accuracy: 0.7225 - val_loss: 0.0140 - val_accuracy: 0.6985\n",
            "Epoch 5/30\n",
            "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0099 - accuracy: 0.7389 - val_loss: 0.0130 - val_accuracy: 0.7170\n",
            "Epoch 6/30\n",
            "6000/6000 [==============================] - 17s 3ms/step - loss: 0.0084 - accuracy: 0.7414 - val_loss: 0.0122 - val_accuracy: 0.7150\n",
            "Epoch 7/30\n",
            "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0074 - accuracy: 0.7402 - val_loss: 0.0118 - val_accuracy: 0.7424\n",
            "Epoch 8/30\n",
            "6000/6000 [==============================] - 16s 3ms/step - loss: 0.0065 - accuracy: 0.7412 - val_loss: 0.0116 - val_accuracy: 0.7577\n",
            "Epoch 9/30\n",
            "6000/6000 [==============================] - 17s 3ms/step - loss: 0.0056 - accuracy: 0.7379 - val_loss: 0.0117 - val_accuracy: 0.7337\n",
            "Epoch 10/30\n",
            "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0051 - accuracy: 0.7407 - val_loss: 0.0116 - val_accuracy: 0.7444\n",
            "Epoch 11/30\n",
            "6000/6000 [==============================] - 17s 3ms/step - loss: 0.0045 - accuracy: 0.7439 - val_loss: 0.0115 - val_accuracy: 0.7157\n",
            "Epoch 12/30\n",
            "6000/6000 [==============================] - 16s 3ms/step - loss: 0.0041 - accuracy: 0.7384 - val_loss: 0.0113 - val_accuracy: 0.7462\n",
            "Epoch 13/30\n",
            "6000/6000 [==============================] - 17s 3ms/step - loss: 0.0037 - accuracy: 0.7379 - val_loss: 0.0113 - val_accuracy: 0.7223\n",
            "Epoch 14/30\n",
            "6000/6000 [==============================] - 16s 3ms/step - loss: 0.0034 - accuracy: 0.7331 - val_loss: 0.0124 - val_accuracy: 0.7405\n",
            "Epoch 15/30\n",
            "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0032 - accuracy: 0.7389 - val_loss: 0.0113 - val_accuracy: 0.7314\n",
            "Epoch 16/30\n",
            "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0029 - accuracy: 0.7403 - val_loss: 0.0114 - val_accuracy: 0.7458\n",
            "Epoch 17/30\n",
            "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0027 - accuracy: 0.7385 - val_loss: 0.0115 - val_accuracy: 0.7447\n",
            "Epoch 18/30\n",
            "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0025 - accuracy: 0.7254 - val_loss: 0.0113 - val_accuracy: 0.6808\n",
            "Epoch 19/30\n",
            "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0023 - accuracy: 0.7270 - val_loss: 0.0117 - val_accuracy: 0.7211\n",
            "Epoch 20/30\n",
            "6000/6000 [==============================] - 17s 3ms/step - loss: 0.0023 - accuracy: 0.7370 - val_loss: 0.0115 - val_accuracy: 0.7144\n",
            "Epoch 21/30\n",
            "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0021 - accuracy: 0.7240 - val_loss: 0.0115 - val_accuracy: 0.7081\n",
            "Epoch 22/30\n",
            "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0020 - accuracy: 0.7288 - val_loss: 0.0118 - val_accuracy: 0.7243\n",
            "Epoch 23/30\n",
            "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0019 - accuracy: 0.7375 - val_loss: 0.0123 - val_accuracy: 0.7525\n",
            "Epoch 24/30\n",
            "6000/6000 [==============================] - 17s 3ms/step - loss: 0.0019 - accuracy: 0.7383 - val_loss: 0.0123 - val_accuracy: 0.7063\n",
            "Epoch 25/30\n",
            "6000/6000 [==============================] - 16s 3ms/step - loss: 0.0018 - accuracy: 0.7341 - val_loss: 0.0114 - val_accuracy: 0.7271\n",
            "Epoch 26/30\n",
            "6000/6000 [==============================] - 17s 3ms/step - loss: 0.0017 - accuracy: 0.7377 - val_loss: 0.0114 - val_accuracy: 0.7382\n",
            "Epoch 27/30\n",
            "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0016 - accuracy: 0.7450 - val_loss: 0.0116 - val_accuracy: 0.7261\n",
            "Epoch 28/30\n",
            "6000/6000 [==============================] - 18s 3ms/step - loss: 0.0016 - accuracy: 0.7373 - val_loss: 0.0129 - val_accuracy: 0.6838\n",
            "Epoch 29/30\n",
            "6000/6000 [==============================] - 19s 3ms/step - loss: 0.0016 - accuracy: 0.7325 - val_loss: 0.0123 - val_accuracy: 0.7181\n",
            "Epoch 30/30\n",
            "6000/6000 [==============================] - 17s 3ms/step - loss: 0.0015 - accuracy: 0.7384 - val_loss: 0.0119 - val_accuracy: 0.7162\n",
            "Test loss: 0.01191060058772564\n",
            "Test accuracy: 0.7161999940872192\n"
          ]
        }
      ]
    }
  ]
}